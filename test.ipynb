{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg', encoding='utf-8-sig')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c313b1fe69cb:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1ab6c97978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Process song_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(artist_id='ARJIE2Y1187B994AB7', artist_latitude=None, artist_location='', artist_longitude=None, artist_name='Line Renaud', duration=152.92036, num_songs=1, song_id='SOUPIRU12A6D4FA1E1', title='Der Kleine Dompfaff', year=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get filepath to song data file\n",
    "input_data = \"s3a://udacity-dend/\"\n",
    "#song_data = 's3a://udacity-dend/song_data/A/B/C/TRABCEI128F424C983.json'\n",
    "song_data = os.path.join(input_data, 'song_data/A/B/C/TRABCEI128F424C983.json')    \n",
    "# read song data file\n",
    "df = spark.read.json(song_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(song_id='SOUPIRU12A6D4FA1E1', title='Der Kleine Dompfaff', artist_id='ARJIE2Y1187B994AB7', year=0, duration=152.92036)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table = df.select(['song_id', 'title', 'artist_id', 'year', 'duration'])\n",
    "songs_table.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_data = 's3a://raywong-bucket-one'\n",
    "songsParquetPath = os.path.join(output_data, \"songs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write songs table to parquet files partitioned by year and artist\n",
    "output_data = 's3a://raywong-bucket-one'\n",
    "songs_path = os.path.join(output_data, \"songs\")\n",
    "songs_table = df.write.mode('overwrite').partitionBy('year','artist_id').parquet(songs_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "artists_table = df.select(col('artist_name').alias('name'), col('artist_location').alias('location'), col('artist_latitude').alias('latitude'), col('artist_longitude').alias('longitude'))\n",
    "artists_path = os.path.join(output_data, \"artists\") \n",
    "# write artists table to parquet files\n",
    "artists_table = df.write.mode('overwrite').parquet(artists_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Process log_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(artist='Fu', auth='Logged In', firstName='Kevin', gender='M', itemInSession=1, lastName='Arellano', length=280.05832, level='free', location='Harrisburg-Carlisle, PA', method='PUT', page='NextSong', registration=1540006905796.0, sessionId=514, song='Ja I Ty', status=200, ts=1542069637796, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"', userId='66')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get filepath to log data file\n",
    "log_data = os.path.join(input_data, 'log_data/2018/11/2018-11-13-events.json')\n",
    "# read log data file\n",
    "df = spark.read.json(log_data)    \n",
    "# filter by actions for song plays\n",
    "df = df.filter(df.page=='NextSong')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns for users table    \n",
    "users_table = df.select(col('userId').alias('user_id'), col('firstName').alias('first_name'), col('lastName').alias('last_name'), 'gender', 'level')\n",
    "    \n",
    "# write users table to parquet files\n",
    "users_path = os.path.join(output_data, \"users\") \n",
    "users_table = df.write.mode('overwrite').parquet(users_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(artist='Fu', auth='Logged In', firstName='Kevin', gender='M', itemInSession=1, lastName='Arellano', length=280.05832, level='free', location='Harrisburg-Carlisle, PA', method='PUT', page='NextSong', registration=1540006905796.0, sessionId=514, song='Ja I Ty', status=200, ts=1542069637796, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"', userId='66', start_time='1542069637', datetime='1542069637', hour=None, day=None, week=None, month=None, year=None, weekday=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda x: str(int(x) // 1000))\n",
    "\n",
    "df = df.withColumn(\"start_time\", get_timestamp(df.ts))\n",
    "    \n",
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda x: datetime.fromtimestamp(int(x) // 1000))\n",
    "df = df.withColumn(\"datetime\", get_timestamp(df.ts))\n",
    "    \n",
    "df = df.withColumn('hour', hour('datetime'))\n",
    "df = df.withColumn('day', dayofmonth('datetime'))\n",
    "df = df.withColumn('week', weekofyear('datetime'))\n",
    "df = df.withColumn('month', month('datetime'))\n",
    "df = df.withColumn('year', year('datetime'))\n",
    "df = df.withColumn('weekday', dayofweek('datetime'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create time table \n",
    "time_table = df.select('start_time', 'hour', 'day', 'week', 'month', 'year', 'weekday')\n",
    "    \n",
    "# write time table to parquet files partitioned by year and month\n",
    "time_path = os.path.join(output_data, \"time\")\n",
    "time_table = df.write.mode('overwrite').partitionBy('year','month').parquet(time_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in song data to use for songplays table\n",
    "song_data = os.path.join(input_data, 'song_data/A/B/C/TRABCEI128F424C983.json')  \n",
    "song_df = spark.read.json(song_data)\n",
    "song_df = song_df.withColumnRenamed('year', 'year_song')\n",
    "song_df.columns\n",
    "# extract columns from joined song and log datasets to create songplays table \n",
    "song_log_df = df.join(song_df, (song_df.artist_name == df.artist) & (song_df.title == df.song))\n",
    "\n",
    "songplays_table = song_log_df.select('start_time', col('userId').alias('user_id'), 'level', 'song_id', 'artist_id', \\\n",
    "                            col('sessionId').alias('session_id'), 'location', col('userAgent').alias('user_agent'))\n",
    "\n",
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_path = os.path.join(output_data, \"songplays\")\n",
    "songplays_table = song_log_df.write.mode('overwrite').partitionBy('year','month').parquet(songplays_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
